{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 14, "column": 0}, "map": {"version":3,"sources":["file:///Users/kaustubhhiwanj/face_recognation/frontend/src/app/attendance/page.js"],"sourcesContent":["// \"use client\";\n// import React, { useRef, useEffect, useState } from \"react\";\n// import dynamic from \"next/dynamic\";\n// import * as faceapi from \"face-api.js\";\n\n// // Dynamically import webcam to prevent SSR issues\n// const Webcam = dynamic(() => import(\"react-webcam\"), { ssr: false });\n\n// const Attendance = () => {\n//   const webcamRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const [recognizedName, setRecognizedName] = useState(\"\");\n//   const [modelsLoaded, setModelsLoaded] = useState(false);\n\n//   // Load face-api models\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       try {\n//         const MODEL_URL = \"/models\";\n//         console.log(\"ðŸ§  Loading models...\");\n//         await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\n//         await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);\n//         await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);\n//         console.log(\"Models Loaded Successfully!\");\n//         setModelsLoaded(true);\n//       } catch (err) {\n//         console.error(\"Error loading models:\", err);\n//       }\n//     };\n//     loadModels();\n//   }, []);\n\n//   // Real-time detection loop\n//   useEffect(() => {\n//     if (!modelsLoaded) return;\n\n//     let intervalId;\n\n//     const detectFace = async () => {\n//       if (\n//         webcamRef.current &&\n//         webcamRef.current.video &&\n//         webcamRef.current.video.readyState === 4\n//       ) {\n//         const video = webcamRef.current.video;\n//         const canvas = canvasRef.current;\n\n//         // Match canvas to video size\n//         const displaySize = {\n//           width: video.videoWidth,\n//           height: video.videoHeight,\n//         };\n//         faceapi.matchDimensions(canvas, displaySize);\n\n//         // Detect faces\n//         const detections = await faceapi\n//           .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\n//           .withFaceLandmarks();\n\n//         // Resize and draw\n//         const resizedDetections = faceapi.resizeResults(detections, displaySize);\n//         const context = canvas.getContext(\"2d\");\n//         context.clearRect(0, 0, canvas.width, canvas.height);\n\n//         // Draw bounding boxes + landmarks\n//         faceapi.draw.drawDetections(canvas, resizedDetections);\n//         faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\n\n//         console.log(\"ðŸ§ Faces detected:\", detections.length);\n\n//         if (detections.length > 0) {\n//           setRecognizedName(\"Face Detected âœ…\");\n//         } else {\n//           setRecognizedName(\"\");\n//         }\n//       }\n//     };\n\n//     intervalId = setInterval(detectFace, 500); // every 0.5s\n//     return () => clearInterval(intervalId);\n//   }, [modelsLoaded]);\n\n//   return (\n//     <div className=\"min-h-screen flex flex-col items-center justify-center bg-gray-50 p-6\">\n//       <h1 className=\"text-3xl font-bold text-blue-800 mb-6\">\n//         Mark Attendance\n//       </h1>\n\n//       {!modelsLoaded ? (\n//         <p className=\"text-gray-600 text-lg\">Loading models...</p>\n//       ) : (\n//         <div className=\"relative\">\n//           <Webcam\n//             ref={webcamRef}\n//             audio={false}\n//             screenshotFormat=\"image/jpeg\"\n//             className=\"rounded-lg shadow-lg w-96 h-auto\"\n//             mirrored={true}\n//           />\n//           <canvas\n//             ref={canvasRef}\n//             className=\"absolute top-0 left-0 w-96 h-auto\"\n//           />\n//         </div>\n//       )}\n\n//       {recognizedName && (\n//         <p className=\"text-green-700 font-semibold text-lg mt-4\">\n//           {recognizedName}\n//         </p>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default Attendance;\n"],"names":[],"mappings":"AAAA,gBAAgB;AAChB,8DAA8D;AAC9D,sCAAsC;AACtC,0CAA0C;AAE1C,qDAAqD;AACrD,wEAAwE;AAExE,6BAA6B;AAC7B,oCAAoC;AACpC,oCAAoC;AACpC,8DAA8D;AAC9D,6DAA6D;AAE7D,4BAA4B;AAC5B,sBAAsB;AACtB,uCAAuC;AACvC,cAAc;AACd,uCAAuC;AACvC,+CAA+C;AAC/C,sEAAsE;AACtE,uEAAuE;AACvE,wEAAwE;AACxE,sDAAsD;AACtD,iCAAiC;AACjC,wBAAwB;AACxB,uDAAuD;AACvD,UAAU;AACV,SAAS;AACT,oBAAoB;AACpB,YAAY;AAEZ,gCAAgC;AAChC,sBAAsB;AACtB,iCAAiC;AAEjC,sBAAsB;AAEtB,uCAAuC;AACvC,aAAa;AACb,+BAA+B;AAC/B,qCAAqC;AACrC,mDAAmD;AACnD,YAAY;AACZ,iDAAiD;AACjD,4CAA4C;AAE5C,wCAAwC;AACxC,gCAAgC;AAChC,qCAAqC;AACrC,uCAAuC;AACvC,aAAa;AACb,wDAAwD;AAExD,0BAA0B;AAC1B,2CAA2C;AAC3C,0EAA0E;AAC1E,kCAAkC;AAElC,6BAA6B;AAC7B,oFAAoF;AACpF,mDAAmD;AACnD,gEAAgE;AAEhE,6CAA6C;AAC7C,kEAAkE;AAClE,qEAAqE;AAErE,gEAAgE;AAEhE,uCAAuC;AACvC,kDAAkD;AAClD,mBAAmB;AACnB,mCAAmC;AACnC,YAAY;AACZ,UAAU;AACV,SAAS;AAET,+DAA+D;AAC/D,8CAA8C;AAC9C,wBAAwB;AAExB,aAAa;AACb,8FAA8F;AAC9F,+DAA+D;AAC/D,0BAA0B;AAC1B,cAAc;AAEd,2BAA2B;AAC3B,qEAAqE;AACrE,cAAc;AACd,qCAAqC;AACrC,oBAAoB;AACpB,8BAA8B;AAC9B,4BAA4B;AAC5B,4CAA4C;AAC5C,2DAA2D;AAC3D,8BAA8B;AAC9B,eAAe;AACf,oBAAoB;AACpB,8BAA8B;AAC9B,4DAA4D;AAC5D,eAAe;AACf,iBAAiB;AACjB,WAAW;AAEX,6BAA6B;AAC7B,oEAAoE;AACpE,6BAA6B;AAC7B,eAAe;AACf,WAAW;AACX,aAAa;AACb,OAAO;AACP,KAAK;AAEL,6BAA6B","debugId":null}}]
}